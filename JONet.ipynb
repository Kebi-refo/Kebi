{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 307 images belonging to 2 classes.\n",
      "Found 133 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#AIS_DDagnet_new\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define data paths\n",
    "train_dir = r'I:\\csrc16\\second\\Deeplearning\\png_441_images\\fusion\\CLAHE_aniso\\train'\n",
    "val_dir = r'I:\\csrc16\\second\\Deeplearning\\png_441_images\\fusion\\CLAHE_aniso\\test'\n",
    "\n",
    "# Define image size and batch size\n",
    "img_width, img_height = 224, 224\n",
    "batch_size = 16\n",
    "\n",
    "# Define data generators with data augmentation for training and validation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "#new\n",
    "\n",
    "def create_AISNet(input_shape, num_heads=8, key_dim=64):\n",
    "    # Input layer\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Convolutional layers\n",
    "    conv1 = layers.Conv2D(6, (5,5), activation='relu', padding='same')(inputs)\n",
    "    pool1 = layers.MaxPooling2D((2,2))(conv1)\n",
    "    conv2 = layers.Conv2D(16, (5,5), activation='relu', padding='same')(pool1)\n",
    "    pool2 = layers.MaxPooling2D((2,2))(conv2)\n",
    "    conv3 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(pool2)\n",
    "    avgpool1 = layers.AveragePooling2D((2, 2))(conv3)\n",
    "    norm1 = layers.BatchNormalization()(avgpool1)\n",
    "    pool3 = layers.MaxPooling2D((2,2))(conv3)\n",
    "    conv4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    pool4 = layers.MaxPooling2D((2,2))(conv4)\n",
    "    conv5 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    avgpool2 = layers.AveragePooling2D((2, 2))(conv5)\n",
    "    norm2 = layers.BatchNormalization()(avgpool2)\n",
    "\n",
    "    # Generate query, key, and value tensors\n",
    "    query = layers.Conv2D(key_dim, (3, 3), activation='relu')(conv5)\n",
    "    key = layers.Conv2D(key_dim, (3, 3), activation='relu')(conv5)\n",
    "    value = layers.Conv2D(key_dim, (3, 3), activation='relu')(conv5)\n",
    "\n",
    "    # Multi-head attention\n",
    "    multi_head_att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)(query, key, value)\n",
    "\n",
    "    # Flatten and dense layers for multi-head attention output\n",
    "    flat_multi_head_att = layers.Flatten()(multi_head_att)\n",
    "    dense_multi_head_att = layers.Dense(128, activation='relu')(flat_multi_head_att)\n",
    "    drop_multi_head_att = layers.Dropout(0.5)(dense_multi_head_att)\n",
    "\n",
    "    # Flatten and dense layers for norm1\n",
    "    flat2_norm1 = layers.Flatten()(norm1)\n",
    "    dense_norm1 = layers.Dense(128, activation='relu')(flat2_norm1)\n",
    "    drop_norm1 = layers.Dropout(0.5)(dense_norm1)\n",
    "    #dense2_norm1 = layers.Dense(64, activation='relu')(drop_norm1)\n",
    "    #drop2_norm1 = layers.Dropout(0.5)(dense2_norm1)\n",
    "\n",
    "\n",
    "    # Flatten and dense layers for norm2\n",
    "    flat_norm2 = layers.Flatten()(norm2)\n",
    "    dense_norm2 = layers.Dense(128, activation='relu')(flat_norm2)\n",
    "    drop_norm2 = layers.Dropout(0.5)(dense_norm2)\n",
    "    #dense2_norm2 = layers.Dense(64, activation='relu')(drop_norm2)\n",
    "    #drop2_norm2 = layers.Dropout(0.5)(dense2_norm2)\n",
    "\n",
    "\n",
    "    # Concatenate all features\n",
    "    concatenated_features = layers.concatenate([drop_multi_head_att, drop_norm1, drop_norm2])\n",
    "\n",
    "    # Output layer\n",
    "    output = layers.Dense(2, activation='softmax')(concatenated_features)\n",
    "\n",
    "    # Define model\n",
    "    model = models.Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "input_shape = (224, 224, 3)\n",
    "num_classes = 3  # Replace with the actual number of classes in your problem\n",
    "model_mhn = create_AISNet(input_shape)\n",
    "model_mhn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
       }
   ],
   "source": [
    "history = model_mhn.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    validation_data=val_generator\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": " "
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and validation accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy for M_AISNet')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss for M_AISNet')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 307 images belonging to 2 classes.\n",
      "Found 133 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#acc-96.99\n",
    "#AIS_DDagnet_new\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define data paths\n",
    "train_dir = r'I:\\csrc16\\second\\Deeplearning\\png_441_images\\fusion\\CLAHE_aniso\\train'\n",
    "val_dir = r'I:\\csrc16\\second\\Deeplearning\\png_441_images\\fusion\\CLAHE_aniso\\test'\n",
    "\n",
    "# Define image size and batch size\n",
    "img_width, img_height = 224, 224\n",
    "batch_size = 16\n",
    "\n",
    "# Define data generators with data augmentation for training and validation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "def create_AISNet(input_shape, num_heads=8, key_dim=64):\n",
    "    # Input layer\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Convolutional layers\n",
    "    conv1 = layers.Conv2D(6, (5,5), activation='relu', padding='same')(inputs)\n",
    "    pool1 = layers.MaxPooling2D((2,2))(conv1)\n",
    "    conv2 = layers.Conv2D(16, (5,5), activation='relu', padding='same')(pool1)\n",
    "    pool2 = layers.MaxPooling2D((2,2))(conv2)\n",
    "    conv3 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(pool2)\n",
    "    avgpool1 = layers.AveragePooling2D((2, 2))(conv3)\n",
    "    norm1 = layers.BatchNormalization()(avgpool1)\n",
    "    pool3 = layers.MaxPooling2D((2,2))(conv3)\n",
    "    conv4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    pool4 = layers.MaxPooling2D((2,2))(conv4)\n",
    "    conv5 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    avgpool2 = layers.AveragePooling2D((2, 2))(conv5)\n",
    "    norm2 = layers.BatchNormalization()(avgpool2)\n",
    "\n",
    "    # Generate query, key, and value tensors\n",
    "    query = layers.Conv2D(key_dim, (3, 3), activation='relu')(conv5)\n",
    "    key = layers.Conv2D(key_dim, (3, 3), activation='relu')(conv5)\n",
    "    value = layers.Conv2D(key_dim, (3, 3), activation='relu')(conv5)\n",
    "\n",
    "    # Multi-head attention\n",
    "    multi_head_att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)(query, key, value)\n",
    "\n",
    "    # Flatten and dense layers for multi-head attention output\n",
    "    flat_multi_head_att = layers.Flatten()(multi_head_att)\n",
    "    dense_multi_head_att = layers.Dense(128, activation='relu')(flat_multi_head_att)\n",
    "    drop_multi_head_att = layers.Dropout(0.5)(dense_multi_head_att)\n",
    "\n",
    "    # Flatten and dense layers for norm1\n",
    "    flat2_norm1 = layers.Flatten()(norm1)\n",
    "    dense_norm1 = layers.Dense(128, activation='relu')(flat2_norm1)\n",
    "    drop_norm1 = layers.Dropout(0.5)(dense_norm1)\n",
    "    dense2_norm1 = layers.Dense(64, activation='relu')(drop_norm1)\n",
    "    drop2_norm1 = layers.Dropout(0.5)(dense2_norm1)\n",
    "\n",
    "\n",
    "    # Flatten and dense layers for norm2\n",
    "    flat_norm2 = layers.Flatten()(norm2)\n",
    "    dense_norm2 = layers.Dense(128, activation='relu')(flat_norm2)\n",
    "    drop_norm2 = layers.Dropout(0.5)(dense_norm2)\n",
    "    dense2_norm2 = layers.Dense(64, activation='relu')(drop_norm2)\n",
    "    drop2_norm2 = layers.Dropout(0.5)(dense2_norm2)\n",
    "\n",
    "\n",
    "    # Concatenate all features\n",
    "    concatenated_features = layers.concatenate([drop_multi_head_att, drop2_norm1, drop2_norm2])\n",
    "\n",
    "    # Output layer\n",
    "    output = layers.Dense(2, activation='softmax')(concatenated_features)\n",
    "\n",
    "    # Define model\n",
    "    model = models.Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "input_shape = (224, 224, 3)\n",
    "num_classes = 3  # Replace with the actual number of classes in your problem\n",
    "model_mh = create_AISNet(input_shape)\n",
    "model_mh.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
    "source": [
    "history = model_mh.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    validation_data=val_generator\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy for M_AISNet2dense')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss for M_AISNet2dense')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

